clmm(agreement ~ curriculum + (1 | id/question), data = df)
# Initial regression ...
m <- clmm(agreement ~ curriculum + (1 | id/question), data = df)
summary(m)
# Initial regression ...
m <- clmm(agreement ~ curriculum + (1 | id), data = df)
summary(m)
# Initial regression ...
m <- clmm(agreement ~ curriculum + (1 | id), data = df, link = "logit", Hess = TRUE, nAGQ = 1))
# Initial regression ...
m <- clmm(agreement ~ curriculum + (1 | id), data = df, link = "logit", Hess = TRUE, nAGQ = 1)
summary(m)
# Initial regression ...
m <-
clmm(agreement ~ curriculum + cohort + (1 | id) + (1|id:cohort),
data = df, link = "logit", Hess = TRUE, nAGQ = 1)
warnings()
summary(m)
m
summary(m)
n <- clmm(agreement ~ cohort + (1|cohort/id), data = df)
summary(n)
o <- clmm(agreement ~ curriculum + cohort + (1|cohort/id), data = df)
summary(o)
o <- clmm(agreement ~ cohort + (1|cohort/id) + curriculum, data = df)
summary(o)
o
summary(o)
df
summary(n)
# Initial regression ...
a <- clmm(agreement ~ curriculum + (1 | id), data = df)
b <- clmm(agreement ~ cohort + (1|cohort/id), data = df)
c <- clmm(agreement ~ curriculum + cohort + (1|cohort/id), data = df)
d <- clmm(agreement ~ curriculum + cohort + curriculum:cohort + (1|cohort/id), data = df)
d
stargazer(a)
library(stargazer)
stargazer(a)
d
summary(d)
anova(a,b,c,d)
anova(a,b)
anova(b,c)
b <- clmm(agreement ~ cohort + (1|cohort/id), data = df)
c <- clmm(agreement ~ curriculum + cohort + (1|cohort/id), data = df)
anova(b,c)
anova(a,d)
stargazer(a)
# Initial regressions ...
a <- clmm2(agreement ~ curriculum + (1 | id), data = df)
# Initial regressions ...
a <- clmm2(agreement ~ curriculum, RANDOM = ID, data = df)
# Initial regressions ...
a <- clmm2(agreement ~ curriculum, RANDOM = id, data = df)
a
df
names(df)
# Focusing on curriculum effect
clmm(agreeement ~ curriculum + proc_career, data = df)
# Focusing on curriculum effect
clmm(agreement ~ curriculum + proc_career, data = df) %>% summary()
# Focusing on curriculum effect
clmm(agreement ~ curriculum + proc_career + (1|id), data = df) %>% summary()
# Focusing on curriculum effect
clmm(agreement ~ curriculum + proc_career + cohort + (1|id), data = df) %>% summary()
names(df)
# Focusing on curriculum effect
clmm(agreement ~ curriculum + proc_career + interest_level + (1|id), data = df) %>% summary()
# Focusing on curriculum effect
clmm(agreement ~ curriculum + proc_career + interest_level + comfort_dx + (1|id), data = df) %>% summary()
# Focusing on curriculum effect
clmm(agreement ~ curriculum + proc_career + interest_level + comfort_tx + (1|id), data = df) %>% summary()
# Focusing on curriculum effect
clmm(agreement ~ curriculum + proc_career + interest_level + cohort (1|id), data = df) %>% summary()
# Focusing on curriculum effect
clmm(agreement ~ curriculum + proc_career + interest_level + cohort +  (1|id), data = df) %>% summary()
clmm(agreement ~ cohort + (1|id), data = df) %>% summary()
clmm(agreement ~ cohort + curriculum + (1|id), data = df) %>% summary()
anova(a,e)
# Focusing on curriculum effect
e <- clmm(agreement ~ curriculum + proc_career + interest_level + cohort + (1|id), data = df)
anova(a,e)
anova(a,e) %>% summary()
summary(e)
# Focusing on curriculum effect
e <- clmm(agreement ~ curriculum + proc_career + interest_level + (1|id), data = df)
anova(a,e) %>% summary()
summary(e)
anova(a,e)
a
summary(a)
exp(.166)
exp(-1.42)
exp(-1.423)
exp(0.166)
summary(b)
exp(.418)
summary(c)
summary(d)
exp(0.457)
summary(a)
# Long form of data
df_long <-
df[c("id", "curriculum", "question", "correctness", "confidence", "agreement")] %>%
gather(., type, response, -id, -curriculum, -question)
df_long
m <- clmm(factor(response) ~ curriculum + (1 | question) + (1 | id), data = na.omit(df_long), link = "logit", Hess = TRUE, nAGQ = 1)
m
summary(m)
# Data frame of confcordanc
df <-
full_join(demo, df_concordance) %>%
na.omit() %>%
as_tibble()
df$question <- factor(df$question)
df
# Long form of data
df_long <-
df[c("id", "curriculum", "question", "correctness", "confidence", "agreement")] %>%
gather(., type, response, -id, -curriculum, -question)
df_long
unique(df_long$question)
unique(df_long$id)
81 * 20
unique(df_long)
df
glimpse(df)
# Ordinal regression
m <- clmm(factor(agreement) ~ curriculum + (1 | question) + (1 | id), data = na.omit(df), link = "logit", Hess = TRUE, nAGQ = 1)
summary(m)
exp(.18)
df_long$response
df_long$response %>% unique()
df_long %>% print(n=40)
tail(df)
tail(df_long)
length(df_long$id)
length(df_long$id) %>% unique()
df_long$id %>% unique(
)
81 * 20
81 * 20 * 3
df_long
ls()
df_big
df
ls()
# Data
df <-
inner_join(demo[c("id", "cohort", "curriculum", "interest_level", "comfort_dx", "proc_career")], df_concordance, by = "id") %>%
mutate_at(c("id", "question", "agreement"), funs(factor(.))) %>%
na.omit()
df()
df
glimpse(df)
summary(a)
exp(-1.42)
1/.242
a$coefficients
a$coefficients[1]
a$coefficients[1] %>% exp()
summary(a)
profile(a)
profile.clmm(a)
library(clmm)
library(clmm2)
library(ordinal)
# Initial regressions ...
a <- clmm(agreement ~ curriculum + (1 | id), data = df, Hess = TRUE)
a
profile(a)
# Initial regressions ...
a <- clmm(agreement ~ curriculum + (1 | id), data = df, Hess = 1)
a
summary(a)
unlink('4_understand_cache', recursive = TRUE)
knitr::opts_chunk$set(
cache = TRUE,
warning = FALSE,
eval = TRUE,
echo = FALSE,
include = TRUE,
message = FALSE,
options(scipen = 999, digits = 3)
)
options(
xtable.table.placement = "H",
xtable.comment = FALSE
)
exp(a$coefficients[1])
# Table of scores
tabular((cohort + 1) ~ (percent)*Format(digits = 2)*(mean + sd), data = df) %>% latex()
# Combine scores and demographic information
df <- full_join(demo[c("id", "cohort", "curriculum", "proc_career")], df_scores, by = "id") %>% na.omit()
# Table of scores
tabular((cohort + 1) ~ (percent)*Format(digits = 2)*(mean + sd), data = df) %>% latex()
# Combine scores and demographic information
df <- full_join(demo[c("id", "cohort", "curriculum", "proc_career")], df_scores, by = "id") %>% na.omit()
knitr::opts_chunk$set(
cache = TRUE,
warning = FALSE,
eval = TRUE,
echo = FALSE,
include = TRUE,
message = FALSE,
options(scipen = 999, digits = 3)
)
options(
xtable.table.placement = "H",
xtable.comment = FALSE
)
# Libraries
source("1_libraries.R")
# Date intake
source("2_intake.R")
# Data tidying
source("3_tidy.R")
# Combine scores and demographic information
df <- full_join(demo[c("id", "cohort", "curriculum", "proc_career")], df_scores, by = "id") %>% na.omit()
# Table of scores
tabular((cohort + 1) ~ (percent)*Format(digits = 2)*(mean + sd), data = df) %>% latex()
t.test(
df$percent[df$curriculum == "Yes"],
df$percent[df$curriculum == "No"]
)
# Using prior dataframe
ggplot(df, aes(x = cohort, y = percent, fill = cohort)) +
geom_boxplot() +
labs(
title = "Training cohorts and quiz accuracy",
x = "Level of training",
y = "Percent correct"
) +
theme_minimal() +
scale_fill_viridis_d()
# Table of scores
tabular((cohort + 1) ~ (percent)*Format(digits = 2)*(mean + sd), data = df)
styler:::style_active_file()
tabular((cohort + 1) ~ (n <- 1) + comfort_dx + proc_career + curriculum, data = demo)
tabular((cohort + 1) ~ (n = 1) + comfort_dx + proc_career + curriculum, data = demo)
# Confidence level visualization
ggplot(df, aes(x = question, fill = level)) +
facet_wrap(~cohort) +
geom_bar(position = "fill") +
labs(
title = "Distribution of Confidence",
x = "Question identifiers",
y = "Response count distribution",
caption = "Each question subgroup (e.g. CS, CF, CV, VF, VS) are in increasing difficulty"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_viridis_d()
# Data needed is overconfidence and demographic
df <- na.omit(inner_join(demo, df_overconfidence, by = "id"))
# Confidence level visualization
ggplot(df, aes(x = question, fill = level)) +
facet_wrap(~cohort) +
geom_bar(position = "fill") +
labs(
title = "Distribution of Confidence",
x = "Question identifiers",
y = "Response count distribution",
caption = "Each question subgroup (e.g. CS, CF, CV, VF, VS) are in increasing difficulty"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_viridis_d()
# Similar data frame as above
ggplot(df, aes(x = level, fill = cohort)) +
facet_wrap(~cohort, ncol = 1) +
geom_bar(aes(y = ..prop.., group = 1), position = "dodge") +
scale_fill_viridis_d() +
theme_minimal() +
coord_flip()
# Data
df <- inner_join(demo, df_concordance, by = "id") %>% na.omit()
df
ls()
df
df_concordance
?gather
# Data
df <- gather(df_concordance[c("id", "question", "correctness", "confidence")], key = "measure", value = "value", -id, -question) %>%
inner_join(demo, ., by = "id") %>%
na.omit()
warnings()
df
summary(df)
df
names(df)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = curriculum, group = measure)) +
geom_bar(aes(y = value), position = "dodge")
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, group = measure)) +
geom_bar(aes(y = value), position = "dodge")
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, group = measure)) +
geom_bar(position = "dodge")
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, group = measure)) +
geom_bar(position = "dodge") +
scale_fill_viridis_d()
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(position = "dodge") +
scale_fill_viridis_d()
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(position = "fill") +
scale_fill_viridis_d(option = "E")
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(position = "fill") +
scale_fill_viridis_d(begin = .2, end = .8)
# Confidence level visualization
ggplot(df, aes(x = question, fill = level)) +
facet_wrap(~cohort) +
geom_bar(position = "fill") +
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = curriculum)) +
facet_wrap(~measure) +
geom_bar(position = "fill") +
scale_fill_viridis_d(begin = .2, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = curriculum)) +
facet_wrap(~measure) +
geom_bar(position = "fill") +
scale_fill_viridis_d(begin = .2, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = curriculum)) +
facet_wrap(~measure) +
geom_bar(position = "fill") +
scale_fill_viridis_d(begin = .3, end = .7)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = curriculum)) +
facet_wrap(~measure) +
geom_bar(position = "dodge") +
scale_fill_viridis_d(begin = .3, end = .7)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = curriculum)) +
facet_wrap(~measure) +
geom_bar(aes(y=..prop.., group=1), position = "dodge") +
scale_fill_viridis_d(begin = .3, end = .7)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
geom_bar(position="dodge") +
scale_fill_viridis_d(begin = .3, end = .7)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
geom_bar(aes(y=..count../sum(..count..)), position="dodge") +
scale_fill_viridis_d(begin = .3, end = .7)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
geom_bar(aes(y=..count../sum(..count..)), position="dodge") +
scale_fill_viridis_d(begin = .2, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
geom_bar(aes(y=..count../sum(..count..)), position="dodge") +
scale_fill_viridis_d(begin = .4, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(aes(y=..count../sum(..count..)), position="dodge") +
scale_fill_viridis_d(begin = .4, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(aes(y=..prop..), position="dodge") +
scale_fill_viridis_d(begin = .4, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(position="dodge") +
scale_fill_viridis_d(begin = .4, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(position="dodge", stat = "summary", fun.y = "mean") +
scale_fill_viridis_d(begin = .4, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(aes(y = value), position="dodge", stat = "summary", fun.y = "mean") +
scale_fill_viridis_d(begin = .4, end = .8)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(aes(y = value), position="dodge", stat = "summary", fun.y = "mean") +
scale_fill_viridis_d(begin = .1, end = .9)
# Visualize confidence and accuracy by curriculum
ggplot(df, aes(x = question, fill = measure)) +
facet_wrap(~curriculum) +
geom_bar(aes(y = value), position="dodge", stat = "summary", fun.y = "mean") +
scale_fill_viridis_d(begin = .2)
# Data needed is overconfidence and demographic
df <- na.omit(inner_join(demo, df_overconfidence, by = "id"))
# Confidence level visualization
ggplot(df, aes(x = question, fill = level)) +
facet_wrap(~cohort) +
geom_bar(position = "fill") +
labs(
title = "Distribution of Confidence",
x = "Question identifiers",
y = "Response count distribution",
caption = "Each question subgroup (e.g. CS, CF, CV, VF, VS) are in increasing difficulty"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_viridis_d()
# Confidence level by curriculum
ggplot(df, aes(x = question, fill = level)) +
facet_wrap(~curriculum) +
geom_bar(position = "fill") +
labs(
title = "Distribution of Confidence",
x = "Question identifiers",
y = "Response count distribution",
caption = "Each question subgroup (e.g. CS, CF, CV, VF, VS) are in increasing difficulty"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_viridis_d()
# Confidence level visualization by cohort
ggplot(df, aes(x = question, fill = level)) +
facet_wrap(~cohort) +
geom_bar(position = "fill") +
labs(
title = "Distribution of Confidence",
x = "Question identifiers",
y = "Response count distribution",
caption = "Each question subgroup (e.g. CS, CF, CV, VF, VS) are in increasing difficulty"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_viridis_d()
# Confidence level by curriculum
ggplot(df, aes(x = question, fill = level)) +
facet_wrap(~curriculum) +
geom_bar(position = "fill") +
labs(
title = "Distribution of Confidence",
x = "Question identifiers",
y = "Response count distribution",
caption = "Each question subgroup (e.g. CS, CF, CV, VF, VS) are in increasing difficulty"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_viridis_d()
# Data needed is overconfidence and demographic
df <- na.omit(inner_join(demo, df_overconfidence, by = "id"))
# Confidence level by curriculum
ggplot(df, aes(x = question, color = level, fill = level)) +
facet_wrap(~curriculum) +
geom_bar(position = "fill") +
labs(
title = "Distribution of Confidence",
x = "Question identifiers",
y = "Response count distribution",
caption = "Each question subgroup (e.g. CS, CF, CV, VF, VS) are in increasing difficulty"
) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
scale_fill_viridis_d() +
scale_color_viridis_d()
# Libraries
source("1_libraries.R")
# Date intake
source("2_intake.R")
# Data tidying
source("3_tidy.R")
# Data
df <-
inner_join(demo[c("id", "cohort", "curriculum", "interest_level", "comfort_dx", "proc_career")], df_concordance, by = "id") %>%
mutate_at(c("id", "question", "agreement"), funs(factor(.))) %>%
na.omit()
# Description of data
tabular((curriculum + cohort + 1) ~ (correctness + confidence + agreement)*(mean + sd)*Format(digits = 2), data = df) #%>%
df
df$agreement
df
# Data
df <-
inner_join(demo[c("id", "cohort", "curriculum", "interest_level", "comfort_dx", "proc_career")], df_concordance, by = "id") %>%
mutate_at(c("id", "question"), funs(factor(.))) %>%
na.omit()
# Description of data
tabular((curriculum + cohort + 1) ~ (correctness + confidence + agreement)*(mean + sd)*Format(digits = 2), data = df) #%>%
# Data
df <-
inner_join(demo[c("id", "cohort", "curriculum", "interest_level", "comfort_dx", "proc_career")], df_concordance, by = "id") %>%
mutate_at(c("id", "question"), funs(factor(.))) %>%
na.omit()
# Initial regressions ...
a <- clmm(agreement ~ curriculum + (1 | id), data = df, Hess = 1)
# Initial regressions ...
a <- clmm(factor(agreement) ~ curriculum + (1 | id), data = df, Hess = 1)
clmm(factor(agreement) ~ curriculum + (1}id) + (1|cohort/curriculum), data = df, Hess = 1)
clmm(factor(agreement) ~ curriculum + (1|id) + (1|cohort/curriculum), data = df, Hess = 1)
f <- clmm(factor(agreement) ~ curriculum + cohort +  (1|cohort/id) + (1|cohort/curriculum), data = df, Hess = 1)
f
summary(f)
1/exp(-1.16)
exp(-1.16)
summary(e)
e <- clmm(factor(agreement) ~ curriculum + cohort + curriculum:cohort + (1 | cohort / id), data = df)
summary(e)
